{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/minpeter/.anaconda3/envs/python313/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:17<00:00,  3.53s/it]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, Gemma3ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "model_id = \"google/gemma-3-12b-it\"\n",
    "\n",
    "model = Gemma3ForConditionalGeneration.from_pretrained(\n",
    "    model_id, device_map=\"auto\"\n",
    ").eval()\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'function', 'function': {'name': 'get_weather', 'description': 'Get the current weather in a given location.', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': \"Enter the 'city name' to get the weather. e.g. 'London'\"}, 'unit': {'type': 'string', 'description': \"Enter the unit of temperature. e.g. 'metric', 'imperial', 'standard'\", 'default': 'metric'}}, 'required': ['location']}}}, {'type': 'function', 'function': {'name': 'get_location', 'description': \"Returns the current location based on the user's device information.\", 'parameters': {'type': 'object', 'properties': {}}}}]\n"
     ]
    }
   ],
   "source": [
    "# Define the function schema\n",
    "\n",
    "tools_get_weather = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get the current weather in a given location.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Enter the 'city name' to get the weather. e.g. 'London'\",\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Enter the unit of temperature. e.g. 'metric', 'imperial', 'standard'\",\n",
    "                    \"default\": \"metric\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "tools_get_location = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_location\",\n",
    "        \"description\": \"Returns the current location based on the user's device information.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {}\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "tools = [tools_get_weather, tools_get_location]\n",
    "print(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"get_weather\", \"arguments\": {'location': {'type': 'string', 'description': \"Enter the 'city name' to get the weather. e.g. 'London'\", 'required': True}, 'unit': {'type': 'string', 'description': \"Enter the unit of temperature. e.g. 'metric', 'imperial', 'standard'\", 'required': False}}, \"description\": \"Get the current weather in a given location.\"}, {\"name\": \"get_location\", \"arguments\": {}, \"description\": \"Returns the current location based on the user's device information.\"}\n",
      "\n",
      "{'$defs': {'FunctionCall': {'properties': {'name': {'title': 'Name', 'type': 'string'}, 'arguments': {'title': 'Arguments', 'type': 'object'}}, 'required': ['name', 'arguments'], 'title': 'FunctionCall', 'type': 'object'}}, 'items': {'$ref': '#/$defs/FunctionCall'}, 'title': 'FunctionCalls', 'type': 'array'}\n",
      "\n",
      "Agentic model with function call capability.\n",
      "Do not explicitly state that you call tools or functions to a user.\n",
      "If the response can be generated from your internal knowledge which is self-evident or does not change over time, do so.\n",
      "The available tools are: {\"name\": \"get_weather\", \"arguments\": {'location': {'type': 'string', 'description': \"Enter the 'city name' to get the weather. e.g. 'London'\", 'required': True}, 'unit': {'type': 'string', 'description': \"Enter the unit of temperature. e.g. 'metric', 'imperial', 'standard'\", 'required': False}}, \"description\": \"Get the current weather in a given location.\"}, {\"name\": \"get_location\", \"arguments\": {}, \"description\": \"Returns the current location based on the user's device information.\"}\n",
      "If you decide to perform a function call, respond in the format below:\n",
      "```toolcall\n",
      "[\n",
      "    {'name': <function-name>, 'arguments': <args-dict>}\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import jinja2\n",
    "from pydantic import BaseModel, RootModel\n",
    "from typing import List\n",
    "\n",
    "class FunctionCall(BaseModel):\n",
    "    name: str\n",
    "    arguments: dict\n",
    "\n",
    "class FunctionCalls(RootModel[List[FunctionCall]]):\n",
    "    pass\n",
    "\n",
    "tools_template = jinja2.Template(\n",
    "\"\"\"\n",
    "{%- for tool in tools %}\n",
    "    {%- set arguments = {} %}\n",
    "    {%- if tool.function.parameters.properties %}\n",
    "        {%- for key, value in tool.function.parameters.properties.items() %}\n",
    "            {%- set required = tool.function.parameters.required | default([]) %}\n",
    "            {%- set is_required = key in required %}\n",
    "            {%- set _ = arguments.update({key: {\"type\": value.type, \"description\": value.description, \"required\": is_required}}) %}\n",
    "        {%- endfor %}\n",
    "    {%- endif %}\n",
    "\n",
    "    {{- '{\"name\": \"%s\", \"arguments\": %s, \"description\": \"%s\"}' % (tool.function.name, arguments, tool.function.description) }}\n",
    "\n",
    "    {%- if not loop.last %}\n",
    "        {{- ', ' }}\n",
    "    {%- endif %}\n",
    "{%- endfor %}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "## system_template = jinja2.Template(\n",
    "# \"\"\"\n",
    "# Agentic model with function call capability.\n",
    "# You can call one or more functions to support user queries.\n",
    "# Do not make any assumptions about what values will be passed to the functions.\n",
    "# Try to solve the problem through function calls rather than questions.\n",
    "# The available tools are: {{ tools }}\n",
    "# If you decide to perform a function call, respond in the format below:\n",
    "# ```toolcall\n",
    "# [\n",
    "#     {'name': <function-name>, 'arguments': <args-dict>}\n",
    "# ]\n",
    "# ```\n",
    "# \"\"\".strip()\n",
    "# )\n",
    "\n",
    "system_template = jinja2.Template(\n",
    "\"\"\"\n",
    "Agentic model with function call capability.\n",
    "Do not explicitly state that you call tools or functions to a user.\n",
    "If the response can be generated from your internal knowledge which is self-evident or does not change over time, do so.\n",
    "The available tools are: {{ tools }}\n",
    "If you decide to perform a function call, respond in the format below:\n",
    "```toolcall\n",
    "[\n",
    "    {'name': <function-name>, 'arguments': <args-dict>}\n",
    "]\n",
    "```\n",
    "\"\"\".strip()\n",
    ")\n",
    "\n",
    "tools_string = tools_template.render(tools=tools)\n",
    "print(tools_string)\n",
    "print()\n",
    "\n",
    "function_schema = FunctionCalls.model_json_schema()\n",
    "print(function_schema)\n",
    "print()\n",
    "\n",
    "system_prompt = system_template.render(tools=tools_string, pydantic_model=function_schema)\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>user\n",
      "Agentic model with function call capability.\n",
      "Do not explicitly state that you call tools or functions to a user.\n",
      "If the response can be generated from your internal knowledge which is self-evident or does not change over time, do so.\n",
      "The available tools are: {\"name\": \"get_weather\", \"arguments\": {'location': {'type': 'string', 'description': \"Enter the 'city name' to get the weather. e.g. 'London'\", 'required': True}, 'unit': {'type': 'string', 'description': \"Enter the unit of temperature. e.g. 'metric', 'imperial', 'standard'\", 'required': False}}, \"description\": \"Get the current weather in a given location.\"}, {\"name\": \"get_location\", \"arguments\": {}, \"description\": \"Returns the current location based on the user's device information.\"}\n",
      "If you decide to perform a function call, respond in the format below:\n",
      "```toolcall\n",
      "[\n",
      "    {'name': <function-name>, 'arguments': <args-dict>}\n",
      "]\n",
      "```\n",
      "\n",
      "y = 3\n",
      "60 / (x + y) = 12\n",
      "이 식에서 x는 뭐야?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "x = 2\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": system_prompt}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        # \"content\": [{\"type\": \"text\", \"text\": \"Where am I?\"}] # single (get_location)\n",
    "        # \"content\": [{\"type\": \"text\", \"text\": \"What's the weather like in Seoul right now?\"}] # single (get_weather)\n",
    "        # \"content\": [{\"type\": \"text\", \"text\": \"What's the weather like in Seoul and London right now?\"}] # parallel (get_weather)\n",
    "        # \"content\": [{\"type\": \"text\", \"text\": \"What's the weather like in my current location?\"}] # nested (get_location -> get_weather)\n",
    "        # \"content\": [{\"type\": \"text\", \"text\": \"I want to know my current location and the current weather in Seattle, New York and London.\"}] # mixed parallel (x4 calls)\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"y = 3\\n60 / (x + y) = 12\\n이 식에서 x는 뭐야?\"}] # irrelevance (expecting text response)\n",
    "        # \"content\": [{\"type\": \"text\", \"text\": \"안녕?\"}] # multi-lingual multi-turn\n",
    "    # },\n",
    "    # {\n",
    "    #     \"role\": \"assistant\",\n",
    "    #     \"content\": [{\"type\": \"text\", \"text\": \"안녕하세요, 무엇을 도와드릴까요?\"}]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"role\": \"user\",\n",
    "    #     \"content\": [{\"type\": \"text\", \"text\": \"날씨 어때?\"}]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(processor.apply_chat_template(\n",
    "    messages, add_generation_prompt=True, tokenize=False,\n",
    "    return_dict=True, return_tensors=\"pt\"\n",
    "))\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages, add_generation_prompt=True, tokenize=True,\n",
    "    return_dict=True, return_tensors=\"pt\"\n",
    ").to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "input_len = inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "with torch.inference_mode():\n",
    "    generation = model.generate(**inputs, max_new_tokens=100, do_sample=True, temperature=1.0)\n",
    "    generation = generation[0][input_len:]\n",
    "\n",
    "decoded = processor.decode(generation, skip_special_tokens=True)\n",
    "print(decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
